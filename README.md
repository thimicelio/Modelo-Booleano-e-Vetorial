# SRI Simplificado (Booleano + EspaÃ§o Vetorial)

Projeto acadÃªmico de um Sistema de RecuperaÃ§Ã£o de InformaÃ§Ã£o (SRI) com:
- **IndexaÃ§Ã£o** de 20 artigos cientÃ­ficos
- **Armazenamento** estruturado (dicionÃ¡rio de termos, tabela de documentos, TF/DF/IDF)
- **Busca** pelos modelos **Booleano** e **EspaÃ§o Vetorial (TF-IDF + cosseno)**
- **Interface grÃ¡fica** em Streamlit

## ğŸ“ Estrutura de pastas

```
/sri/
 â”œâ”€ data/
 â”‚   â””â”€ raw/                 # PDFs originais
 â”œâ”€ storage/                 # Ã­ndices e metadados gerados (.json)
 â”œâ”€ stopwords/
 â”‚   â””â”€ stopwords.txt        # lista de stopwords (UTF-8)
 â””â”€ src/
     â”œâ”€ preprocess.py        # normaliza/tokeniza/remove stopwords
     â”œâ”€ index.py             # TF por doc, dicionÃ¡rio global, DF/IDF
     â”œâ”€ search_boolean.py    # busca booleana (AND/OR/NOT)
     â”œâ”€ search_vector.py     # busca vetorial (TF-IDF + cosseno)
     â””â”€ app.py               # interface Streamlit
```

## âœ… PrÃ©-requisitos

- Python 3.9+
- Pip atualizado (`python -m pip install --upgrade pip`)

## ğŸ“¦ InstalaÃ§Ã£o

Via `pip` (direto):
```bash
pip install -r requirements.txt
```
Ou se preferir manuealmente: 

```bash
pip install streamlit pdfminer.six nltk
```

Ou crie um ambiente virtual e instale:

```bash
# Windows (PowerShell)
python -m venv .venv
.venv\Scripts\Activate.ps1
pip install streamlit pdfminer.six nltk

# macOS / Linux
python3 -m venv .venv
source .venv/bin/activate
pip install streamlit pdfminer.six nltk
```

## ğŸ—‚ï¸ PreparaÃ§Ã£o dos dados

1. Coloque seus **PDFs** em `data/raw/`.
2. Garanta que `stopwords/stopwords.txt` estÃ¡ salvo

## ğŸ”§ GeraÃ§Ã£o dos Ã­ndices

Arquivos gerados (exemplos):
- `storage/docs_raw.json` â€” metadados e resumos extraÃ­dos
- `storage/docs_processed.json` â€” tokens/contagens por doc
- `storage/index.json` â€” TF por doc, dicionÃ¡rio global, DF/IDF e tabela de docs

## â–¶ï¸ Executando a interface

```bash
streamlit run src/app.py
```

- Se a porta 8501 estiver ocupada:
  ```bash
  streamlit run src/app.py --server.port 8502
  ```

## ğŸ” Como usar

1. Abra o app no navegador (link que o Streamlit mostra).
2. Digite sua consulta no campo **Consulta**.
3. Escolha o **Modelo**:
   - **Booleano**: use `AND`, `OR`, `NOT`  
     Ex.: `aprendizagem AND profunda NOT revisÃ£o`
   - **EspaÃ§o Vetorial**: termos livres; a ordenaÃ§Ã£o Ã© por similaridade cosseno (TF-IDF).  
     Ex.: `reconhecimento de fala robusto`

Os resultados aparecem com **TÃ­tulo**, **Autores** e **score** (no caso do vetorial). Clique para ver detalhes.

## ğŸ“ Requisitos atendidos

- **DicionÃ¡rio de termos** com quantidade total de ocorrÃªncias (em `storage/index.json` â†’ `dicionario_termos_total`)
- **Tabela de documentos** `<DocId, TÃ­tulo, Autor, TotPal>` (em `doc_table`)
- **Registro `<DocId, TotPal>`** + Ãºltimo identificador (em `registro_docid_totpal`)
- **Documento original armazenado** (seus PDFs em `data/raw/`)
- **TF** por documento (em `tf_by_doc`) e **IDF** (em `idf`)
- **Interface grÃ¡fica** para os dois modelos

## ğŸ§¯ Troubleshooting

**Erro de encoding na stoplist (Windows):**  
`UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe0 ...`  
â†’ Abra `stopwords/pt.txt` no VS Code/Notepad++ e **salve como UTF-8** (sem BOM).  
Se preferir tolerar encodings automaticamente, adapte a funÃ§Ã£o de leitura de stopwords (ex.: tentar `utf-8`, `utf-8-sig`, `cp1252`, `latin-1`).

**Resultados vazios no app:**  
- Confirme se rodou `ingest.py`, `preprocess.py` e `index.py`.
- Verifique se hÃ¡ PDFs em `data/raw/`.
- Confira se os resumos foram detectados (regex de `Resumo/Abstract` pode precisar ajuste conforme seus PDFs).

## ğŸ§© PersonalizaÃ§Ãµes sugeridas

- Ampliar lista de stopwords (`stopwords/pt.txt`)
- Ajustar heurÃ­sticas de extraÃ§Ã£o em `ingest.py` (tÃ­tulo, autores, filiaÃ§Ã£o, resumo, palavras-chave)
- Adicionar suporte a parÃªnteses na consulta booleana
- Exportar resultados (CSV/JSON) via Streamlit

## ğŸ“š LicenÃ§a

Uso acadÃªmico/educacional.
